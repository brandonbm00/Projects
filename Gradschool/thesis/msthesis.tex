%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[adobe-utopia]{mathdesign}
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands

\usepackage{braket}
\usepackage{cancel}

\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps


\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{Northwestern University} \\ [25pt] % Your us get downniversity, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge GPU Accelerated Parameter Estimation of Gravitational Waves from Binary Black Hole Mergers \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Brandon B. Miller, Masters Thesis} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title
\newpage
\section{Background and Motivation}

Gravitational waves are predicted as a mathematical consequence of the linearized Einstein Field Equations. The Einstein Field Equations themselves are a set of ten unique, coupled, nonlinear partial differential equations.  

\subsection{Pieces of the Einstein Equation}
\subsubsection{Reimann Tensor}
The Reimann Tensor is a mathematical object that encapsulates the geometric \textit{curvature} of spacetime. The concept of a curved spacetime is fundamentally no different from the concept of a curved space, and from examining the behavior of vectors in such a space we can address both the purpose and properties of the Reimann tensor without departing from the intuitive picture of spheres and arrows.

The Reimann tensor is traditionally derived by examining the local behavior of geodesics subject to a metric tensor that describes curved space. Here we motivate the concept with a visual explanation of parallel transport. Consider a vector pointing in some arbitrary direction $\sigma$ somewhere on the sphere, as depicted in figure \textbf{FIGURE HERE}. If we maintain the orientation of the vector relative to the surface of the sphere as we traverse the path, we note that the vector behaves differently depending on the order in which we choose to traverse the directions $\mu$ and $\nu$. This difference is representable by a vector that points between the two tips - one that is dependent on the initial direction $\sigma$ and both the transport directions $\mu$ and $\nu$. Let this vector be denoted $\vec{d}$. Then the Reimann tensor, $R_{\rho \sigma \mu \nu}$, is simply $d_{\rho}$, the $\rho$'th component of this difference vector. From this geometric picture some of the classical symmetries that are often introduced abreast the definition of the Reimann tensor are immediately intuitive, such as the skew symmetry depicted in figure \textbf{FIGURE HERE}.
Since it is somewhat unfair (worse - \textit{incorrect}) to characterize the entire geometry of the space with looping paths over large areas, the formal definition of the Reimann tensor is in fact the infinitesimal version of the concept above. Indeed, the concept of a single direction one may traverse is only valid in a small region of curved space, so the real Reimann tensor must describe the difference between two vectors as parallel transported around an infinitesimally small version of the original loop. It follows then how there must be a (possibly different) Reimann tensor at each point on the manifold in question. More remarkable however is the simplicity of the formal definition within this picture:

\begin{align}
R^{\rho}_{\sigma \mu \nu}\partial_{\rho} = \left(\nabla_{\mu}\nabla{\nu} - \nabla_{\nu}\nabla_{\mu}\right)\partial_{\sigma}
\end{align} 

It should be noted that the above formula is true only modulo a term containing $\nabla_{[\mu, \nu]}$ except in the special case of coordinate vector fields, where it is zero. Although it does little to redeem it as a first explanation of the concept, this also illuminates why the Reimann tensor is sometimes described as encoding the non-commutativity of covariant derivatives on a manifold. Somewhat more subtle is the explicit role of the Reimann tensor in describing geodesic deviation. Crucial to a straightforward linearization of the Reimann tensor itself is the expression in terms of the Christoffel Symbols \textbf{AS DEFINED IN APPENDIX}

\begin{align}
R^{\rho}_{\sigma \mu \nu} = \partial_{\mu}\Gamma^{\rho}_{\nu \sigma} - \partial_{\nu}\Gamma^{\rho}_{\mu \sigma} + \Gamma^{\rho}_{\mu \lambda}\Gamma^{\lambda}_{\nu \sigma} - \Gamma^{\rho}_{\nu \lambda}\Gamma^{\lambda}_{\mu \sigma}
\end{align}

The christoffel symbols contain some information about the curvature of space as a function of the coordinates, and thus in the framework of linearized gravity products of Christoffel symbols are second order:   

\begin{align}
R^{\rho}_{\sigma \mu \nu} = \partial_{\mu}\Gamma^{\rho}_{\nu \sigma} - \partial_{\nu}\Gamma^{\rho}_{\mu \sigma} 
\end{align}




If $x^{\rho}(\tau)$ are the components of a geodesic parameterized by $\tau$, then $\dot{x^{\rho}}(\tau) \equiv T^{\rho}$ are the components of a vector tangent to the geodesic. Suppose there is a family such nearby geodesics indexed by some other parameter, $s$, and that we can define \textit{deviation vector} $S^{\rho}(\tau) = \partial_{s}x^{rho}(s,\tau)$ which characterizes the separation between nearby geodesics. It can be shown that the second derivative of this vector with respect to $\tau$ is related to the Reimann tensor through the differential equation
 

\begin{align}
\ddot{S^{\rho}} = R^{\rho}_{\sigma \mu \nu} T^{\sigma} T^{\mu} S^{\nu}
\end{align} 

\section{Linearized Gravity}

In linearized gravity we assume the spacetime is described by a flat spacetime $g_{\mu \nu}$ plus a small perturbation

\begin{align}
g_{\mu \nu} = \eta_{\mu \nu} + h_{\mu \nu}
\end{align}

Since the other pieces of the Einstein field equations are directly derived from the metric, they must be individually linearized to form a description of spacetime around weak sources. The standard treatment of linearized gravity assumes that to first order we may raise and lower indices using the Minkowski metric. If we tried to use the full form of equation \textbf{EQUATION}, we would have

\begin{align}
g^{\mu}_{\nu} &= g^{\mu \alpha}g_{\alpha \nu} \\
&= (\eta^{\mu \alpha} + h^{\mu \alpha}) (\eta_{\alpha \nu} + h_{\alpha \nu}) \\
&= \eta^{\mu \alpha}\eta_{\alpha \nu} + \eta^{\mu \alpha}h_{\alpha \nu} + h^{\mu \alpha}\eta_{\alpha \nu} + h^{\mu \alpha}h_{\alpha \nu}
\end{align} 

The second two terms being second order in $h$, ther peturbation, are neglected in linearized gravity. We assume from here on that indices can be freely raised and lowered to first order using only the Minkowski metric $\eta_{\mu \nu}$.

\begin{align}
h^\mu_\nu = \eta^{\alpha \mu} h_{\alpha \nu} \ \  \text{and} \ \ h^{\mu \nu} = \eta^{\alpha \mu}\eta^{\beta \nu}h_{\alpha \beta}
\end{align}

The next natural line of logic to pursue is to write down the Christoffel symbols for such a spacetime

\begin{align}
\Gamma^{\mu}_{\alpha \beta} &= \frac{1}{2}g^{\nu \mu}\left[\partial_{\beta}g_{\alpha \nu} + \partial_{\alpha}g_{\beta \nu} - \partial_{\nu}g_{\alpha \beta}\right] \\
&= \frac{1}{2}\left(\eta^{\mu \nu} + h^{\mu \nu}\right)\left[\partial_{\beta}g_{\alpha \nu} + \partial_{\alpha}g_{\beta \nu} - \partial_{\nu}g_{\alpha \beta}\right]
\end{align}

Inserting the expanded form of the metric into the term within the brackets gives us six terms times two at the front, for twelve total. Thankfully, three correspond to the standard flat-space Christoffel symbols which can be made zero through a choice of coordinates (in fact, orthonormal Cartesian coordinates), three involve derivatives of $\eta_{\mu \nu}$ which are zero, and three are second order in $h_{\mu \nu}$, which we assume are zero. This leaves us with three:

\begin{align}
\Gamma^{\mu}_{\alpha \beta} &= \frac{1}{2}\eta^{\mu \nu}\left[\partial_{\beta}h_{\alpha \nu} + \partial_{\alpha} h_{\beta \nu} - \partial_{\nu}h_{\alpha \beta}\right] \\
&= \frac{1}{2} \left[\partial_{\beta} h^{\mu}_{\alpha} + \partial_{\alpha}h_{\beta}^{\mu} - \partial^{\mu}h_{\alpha \beta}\right] 
\end{align} 

Where in the last term $\partial^{\mu} = \eta^{\mu \nu}\partial_{\nu}$ was used to raise the index on the actual partial derivative operator itself. It should be noted at this point that since we neglect terms that are second order in the Christoffel symbols themselves, in linearized gravity, the covariant derivative of a metric perturbation is equivalent to the normal partial derivate. The same assumption allows for simplification of the Reimann and Ricci tensors:

\begin{align}
R^{\rho}_{\mu \sigma \nu} &= \partial_{\sigma}\Gamma^{\rho}_{\mu \nu} - \partial_{\nu}\Gamma^{\rho}_{\mu \sigma} \\
R_{\mu \nu} = R^{\rho}_{\mu \rho \nu} &= \partial_{\rho}\Gamma^{\rho}_{\nu \mu} - \partial_{\mu}\Gamma^{\rho}_{\mu \rho}
\end{align}

Plugging in equation \textbf{EQUATION} we have

\begin{align}
R_{\mu \nu} & = \frac{1}{2}\partial_{\alpha}\left[\partial_{\nu}h^{\alpha}_{\mu} + \partial_{\mu}h^{\alpha}_{\nu} - \partial^{\alpha}h_{\mu \nu}\right] - \frac{1}{2}\partial_{\nu}\left[\partial_{\alpha}h^{\alpha}_{\mu} + \partial_{\mu}h^{\alpha}_{\alpha} - \partial^{\alpha}h_{\mu \alpha}\right] \\
&= \frac{1}{2}\left[ \cancel{\partial_{\alpha}\partial_{\nu}h^{\alpha}_{\mu}} + \partial_{\alpha}\partial_{\mu}h^{\alpha}_{\nu} - \partial_{\alpha}\partial^{\alpha}h_{\mu \nu} - \cancel{\partial_{\nu}\partial_{\alpha}h^{\alpha}_{\mu}} - \partial_{\nu}\partial_{\mu}h^{\alpha}_{\alpha} + \partial_{\nu}\partial^{\alpha}h_{\mu \alpha} \right] \\
&= \frac{1}{2}\left[\partial_{\alpha}\partial_{\mu}h^{\alpha}_{\nu} + \partial_{\nu}\partial^{\alpha}h_{\mu \alpha} - \partial_{\alpha}\partial^{\alpha}h_{\mu \nu} - \partial_{\nu}\partial_{\mu}h^{\alpha}_{\alpha}\right]
\end{align}

The quantity $h^{\alpha}_{\alpha}$ is the trace of the pertubation metric and represents, in a sense, an overall measure of the \textit{strength} or \textit{amplitude} of the perturbation, this is often called just $h$. The term $\partial^{\alpha}\partial_{\alpha}$ is an inner product that when formed through the Minkowski metric becomes the wave operator, $\Box = -\partial_{t}^{2} + \nabla^2$. The Ricci tensor is obtained by contracting the Reimann tensor over the two free indices:

\begin{align}
R \equiv \eta^{\mu \nu}R_{\mu \nu} &= \frac{1}{2}\left[\partial_{\alpha}\partial^{\mu}h_{\mu}^{\alpha} + \partial_{\mu} \partial^{\alpha}h^{\mu}_{\alpha} - \Box h - \Box h\right]
\end{align}

Since $\alpha$ and $\mu$ are summed indices, the first two terms are the same. Dropping the $\frac{1}{2}$, the Ricci scalar curvature is 

\begin{align}
R = \partial_{\alpha}\partial_{\mu}h^{\mu \alpha} - \Box h
\end{align}

Many authors choose to simplify the expression for the Ricci Tensor by defining the quantity

\begin{align}
V_{\nu} = \partial_{\alpha}h^{\alpha}_{\nu} - \frac{1}{2}\partial_{\nu}h
\end{align}

With which the first two terms of the linearized Ricci tensor can be reorganized as

\begin{align}
\partial_{\mu}\partial_{\alpha}h_{\nu}^{\alpha} - \partial_{\mu}\partial_{\nu}h &= \partial_{\mu}\left[\partial_{\alpha}h_{\nu}^{\alpha} - \partial_{\nu}h\right] \\
&= \partial_{\mu}V_{\nu} - \frac{1}{2}\partial_{\mu}\partial_{\nu}h
\end{align}

Which upon substitution into the \textbf{EQUATION} for $R_{\mu \nu}$ yields

\begin{align}
R_{\mu \nu} &= \frac{1}{2}\left[\partial_{\mu}V_{\nu} - \frac{1}{2}\partial_{\mu}\partial_{\nu}h + \partial^{\alpha}\partial_{\nu}h_{\mu \alpha} - \Box h_{\mu \nu}\right]
\end{align}

The two unsimplified terms form the quantity $\partial_{\nu}\left[\partial^{\alpha}h_{\mu \alpha} - \frac{1}{2}\partial_{\mu}h\right]$ which we recognize as $\partial_{\nu}V_{\mu}$, leaving us with

\begin{align}
R_{\mu \nu} = \frac{1}{2}\left[\partial_{\mu}V_{\nu} + \partial_{\nu}V_{\mu} - \Box h_{\mu \nu}\right] 
\end{align}

Setting the right hand side of this equation gives us the linearized, vacuum Einstein Equation $R_{\mu \nu} = 0$:

\begin{align}
\frac{1}{2}\left[\partial_{\mu}V_{\nu} + \partial_{\nu}V_{\mu} - \Box h_{\mu \nu}\right] = 0 
\end{align}

\section{Implementation}
The main weight of the computational work described above falls under an expensive Monte Carlo integration of the evidence as part of the Bayesian posterior. Zooming in it quickly becomes apparent that the main challenge to be overcome is efficient evaluation of the function to be integrated, in this case the factored likelihood. Prior to this work, the factored likelihood is was computed with a series of looping structures that individually compiled all the terms of the equation in an independent and serial manner. The process took substantial advantage of many high level operations available within Python to match up the correct terms across various harmonic mode time series, spherical harmonics, and antenna patterns. Thanks to clever optimization and gratuitous use of fast numerical Python libraries such as NumPy, the code was able to compute approximately $10^3$ likelihood evaluations on the order of seconds, the limiting factor being the serial nature of loops and the inherent lethargy of high level languages such as Python. Although NumPy commonly passes target data to compiled routines written in faster languages such as C, some portions of the computation (in particular the marginalization over time) benefit little from this capability and form a bottleneck for efficient evaluation of the likelihood. Furthermore the original implementation heavily relied upon older structures within the existing LIGO Algorithms Library (LAL), a set of C routines bound to Python through Swig, to perform many intermediate calculations, such as computing spherical harmonics. The goal of the first phase of this work was thorough vectorization of the process used to build the terms of the likelihood utilizing the BLAS subroutines available through NumPy as often as possible, as well as reducing dependency on LAL. To that end, the components of the factored likelihod were reworked. 

\subsection{Complex Antenna Factor}
The complex antenna factor is a complex number that modulates the gravitational wave signal as a function of incoming direction. This is necessary due to the non isotropic sensitivity of the LIGO interferometers themselves. $F_{+}$ and $F_{\times}$. 

\begin{align}
F_{+} &= [R_{0,0}X_0 + R_{0,1}X_1 + R_{0,2}X_2]X_0 - [R_{0,0}Y_0 + R_{0,1}Y_1 + R_{0,2}Y_2]Y_0 \\
&+ [R_{1,0}X_0 + R_{1,1}X_1 + R_{1,2}X_2]X_1 - [R_{1,0}Y_0 + R_{1,1}Y_1 + R_{1,2}Y_2]Y_1 \\
&+ [R_{2,0}X_0 + R_{2,1}X_1 + R_{2,2}X_2]X_2 - [R_{2,0}Y_0 + R_{2,1}Y_1 + R_{2,2}Y_2]Y_2
\end{align}

Collecting all the positive terms of this expression gives
\begin{align}
F_{+} &= R_{0,0}X_0X_0 + R_{0,1}X_0X_1 + R_{0,2}X_0X_2 \\
&+ R_{0,0}X_0X_0 + R_{0,1}X_0X_1 + R_{0,2}X_0X_2 \\ 
&+ R_{0,0}X_0X_0 + R_{0,1}X_0X_1 + R_{0,2}X_0X_2 
\end{align}
At which point we see that the same result is computable as an outer product of the vector $\vec{X}$ using

\begin{align}
F_{+} &= \vec{X}\mathbf{R}\vec{X} - \vec{Y}\mathbf{R}\vec{Y}
\end{align}

And the complex part of the gravitational wave is thus

\begin{align}
F_{\times} &= \vec{X}\mathbf{R}\vec{Y} + \vec{Y}\mathbf{R}\vec{X}
\end{align}

One a sample-to-sample basis, the numbers that vary are the components of the vectors $\vec{X}$ and $\vec{Y}$. Thus we need a function that takes as input a \textit{list} vectors (or \textit{vector}) of vectors and produces a vector with the right components as output. To that end we define the tensor $X^{i}_{j}$ where

\begin{align}
X^i &= 
\begin{bmatrix}
X^{i}_0 \\
X^{i}_1 \\
X^{i}_2
\end{bmatrix}
\end{align}

As well as the tensor $R^{i}_{jk}$ where

\begin{align}
R^{i} &= 
\begin{bmatrix}
R^{i}_{00} & R^{i}_{01} & R^{i}_{02} \\ 
R^{i}_{10} & R^{i}_{11} & R^{i}_{12} \\ 
R^{i}_{20} & R^{i}_{21} & R^{i}_{22}  
\end{bmatrix}
\end{align}

The tensor $X$ is like a stack of all the different possible $\vec{X}$ coming out of the page. The Tensor $R$ is like $n$ copies of the matrix $\mathbf{R}$ stacked on top of each other. In this way the desired vector is obtainable with the tensor contraction

\begin{align}
F^{i}_{+} &= X^{lm}R^{i}_{lj}X^{j}_{m} - Y^{lm}R^{i}_{lj}Y^{j}_{m} \\ 
F^{i}_{\times} &= X^{lm}R^{i}_{lj}Y^{j}_{m} + Y^{lm}R^{i}_{lj}X^{j}_{m} \\ 
\end{align}

\subsection{Vectorized Single Detector Log Likelihood}

With the spherical harmonics and antenna factor in hand the following set of operations yield the factored likelihood for a single detector, the network likelihood being a simple sum over all of the detectors.

Equation 24 from Arxiv $15502.05370v1.pdf$ for the network log likelihood reads 

\begin{align}
\ln{\mathcal{L}} = &\frac{D_{ref}}{D}Re \sum_{k}\sum_{(l,m)}\left[F_k Y_{lm}\right]^{*}Q_{k,lm} \\ 
& - \left[\frac{D_{ref}}{2D}\right]^{2}\sum_{k}\sum_{(l,m),(l',m')}\left[|F_k|^2 Y_{l,m}^{*}Y_{l',m'}U_{k,(l,m),(l'm')}\right] \\
 & - \left[\frac{D_{ref}}{2D}\right]^{2}\sum_{k}\sum_{(l,m),(l',m')}Re\left[  F_{k}^{2}Y_{l,m}Y_{l'm'}V_{k,(l,m),(l'm')}\right]
\end{align}

Consider a single detector, thus dropping the sum over $k$. The first term is of the form $\vec{A}\cdot\vec{B} = \sum_{i=0}^{d}A_iB_i$, so if $Q_{k,(l,m)}$ were a simple vector, we could write it as

\begin{equation}
- \left[\frac{D_{ref}}{2D}\right]^{2}\sum_{k}\sum_{(l,m),(l',m')}\left[|F_k|^2 Y_{l,m}^{*}Y_{l',m'}U_{k,(l,m),(l'm')}\right] = - \left[\frac{D_{ref}}{2D}\right]^{2} F*\vec{Y}\cdot\vec{Q}
\end{equation}

However the $Q_{k,(l,m)}$ are actually harmonic mode time series and not single values. We desire a vector whose values are the likelihoods at each point in the time series. 

Consider the case where we have only the $(2,-2), (2,0)$ and $(2,2)$ modes. If we write all the mode time series $Q^0, Q^1, Q^2...$ as the columns of a matrix , then the desired result is obtained with

\begin{align}
F*
\begin{bmatrix}
Q^0_{2,-2} & Q^0_{2,+0} & Q^0_{2,+2} \\
Q^1_{2,-2} & Q^1_{2,+0} & Q^1_{2,+2} \\ 
Q^2_{2,-2} & Q^2_{2,+0} & Q^2_{2,+2} \\
\vdots & \vdots & \vdots
\end{bmatrix}
\begin{bmatrix}
\left(Y_{2,-2}\right)\\
\hspace{0mm} \\
\left(Y_{2,+0}\right) \\
\hspace{0mm} \\
\left(Y_{2,+2}\right) \\
\end{bmatrix}
=
\begin{bmatrix}
Q^0_{2,-2} Y_{2,-2} + Q^0_{2,-2}Y_{2,+0} + Q^0_{2,+2}Y_{2,+2} \\
Q^1_{2,-2} Y_{2,-2} + Q^1_{2,-2}Y_{2,+0} + Q^1_{2,+2}Y_{2,+2} \\
Q^2_{2,-2} Y_{2,-2} + Q^2_{2,-2}Y_{2,+0} + Q^2_{2,+2}Y_{2,+2} \\
\vdots
\end{bmatrix}
\end{align}

With $\vec{Y}$ and $\mathbf{Q}$ defined as the matrix and vector above respectively, we have for the first term

\begin{equation}
\frac{D_{ref}}{D}Re\left[\mathbf{Q}\left(F\vec{Y}\right)^{*}\right]
\end{equation}

The second term is a sum once over all the possible combinations of $(l,m), (l',m')$ pairs using the $U_{(l,m),(l',m')}$ cross terms. Its result is a scalar quantity made up of terms like

\begin{align}
&Y_{2,-2}^{*}Y_{2,-2}U_{(2,-2),(2,-2)} + Y_{2,-2}^{*}Y_{2,+0}U_{(2,-2),(2,+0)} + Y_{2,-2}^{*}Y_{2,+2}U_{(2,-2),(2,+2)} \\ 
 +  \ &Y_{2,+0}^{*}Y_{2,-2}U_{(2,+0),(2,-2)} + Y_{2,+0}^{*}Y_{2,+0}U_{(2,+0),(2,+0)} + Y_{2,+0}^{*}Y_{2,+2}U_{(2,+0),(2,+2)} \\ 
+ \  &Y_{2,+2}^{*}Y_{2,-2}U_{(2,+2),(2,-2)} + Y_{2,+2}^{*}Y_{2,+0}U_{(2,+2),(2,+0)} + Y_{2,+2}^{*}Y_{2,+2}U_{(2,+2),(2,+2)}
\end{align}


If we pack the $U_{(l,m),(l',m')}$ into the matrix $\mathbf{U}$ as defined below then the following set of matrix operations produces the same sum

\begin{align*}
\begin{bmatrix}
Y_{2,-2}^{*} &Y_{2,+0}^{*}  &Y_{2,+2}^{*}   
\end{bmatrix}
\begin{bmatrix}
U_{(2,-2),(2,-2)} &  U_{(2,-2),(2,+0)} &  U_{(2,-2),(2,+2)} \\
U_{(2,+0),(2,-2)} &  U_{(2,+0),(2,+0)} &  U_{(2,+0),(2,+2)} \\
U_{(2,+2),(2,-2)} &  U_{(2,+2),(2,+0)} &  U_{(2,+2),(2,+2)}
\end{bmatrix}
\begin{bmatrix}
Y_{2,-2} \\
Y_{2,+0} \\
Y_{2,+2}
\end{bmatrix}
\end{align*}

because when you multiply $\mathbf{U}$ into $\vec{Y}$ this simplifies to 



\begin{align*}
\begin{bmatrix}
Y_{2,-2}^{*} &Y_{2,+0}^{*}  &Y_{2,+2}^{*}   
\end{bmatrix}
\begin{bmatrix}
U_{(2,-2),(2,-2)} Y_{2,-2} + U_{(2,-2),(2,-2)}Y_{2,-2} + U_{(2,-2),(2,-2)}Y_{2,-2} \\ 
U_{(2,-2),(2,-2)} Y_{2,-2} + U_{(2,-2),(2,-2)}Y_{2,-2} + U_{(2,-2),(2,-2)}Y_{2,-2} \\ 
U_{(2,-2),(2,-2)} Y_{2,-2} + U_{(2,-2),(2,-2)}Y_{2,-2} + U_{(2,-2),(2,-2)}Y_{2,-2} 
\end{bmatrix}
\end{align*}

Which becomes the desired scalar. This allows us to write the second term as

\begin{align}
- \left[\frac{D_{ref}}{2D}\right]^{2}\sum_{k}\sum_{(l,m),(l',m')}\left[|F_k|^2 Y_{l,m}^{*}Y_{l',m'}U_{k,(l,m),(l'm')}\right] =  - \left[\frac{D_{ref}}{2D}\right]^{2} |F^2|\vec{Y}^{*}\mathbf{U}\vec{Y}
\end{align}

We must always set up the spherical harmonic vectors based on the value of $m$ and the cross terms in row-major form based first on $m_2$ and then on $m_1$. If we organize the matrix $\mathbf{V}$ in the same way then the same set of steps will lead us to conclude that  


\begin{align}
- \left[\frac{D_{ref}}{2D}\right]^{2}\sum_{k}\sum_{(l,m),(l',m')}Re\left[  F_{k}^{2}Y_{l,m}Y_{l'm'}V_{k,(l,m),(l'm')}\right] = - \left[\frac{D_{ref}}{2D}\right]^{2}Re \left[F^2 \vec{Y}\mathbf{V}\vec{Y} \right]
\end{align}

Combining the results the single detector log likelihood is 

\begin{align}
\ln{\mathcal{L}} = \frac{D_{ref}}{D}\Re\left[\mathbf{Q}\left(F\vec{Y}\right)^{*}\right] - \left[\frac{D_{ref}}{2D}\right]^{2}\left[|F|^2 \vec{Y}^{*}\mathbf{U}\vec{Y} - \Re\left(F^2 \vec{Y}\mathbf{V}\vec{Y}\right) \right]
\end{align}

\subsection{GPU Implementation}
Vectorization of the code produces a performance improvement due to SIMD instruction sets available on many modern microprocessor architectures. This allows for some on-chip parallelism that the compiler may use to unroll loops within the machine code and increase efficiency. Beyond this however the process of recasting the computation into clear matrix and tensor operations illuminates a higher level of parallelism possible on the hardware level. A substantial amount of both academc and industrial research and development has centered around efficient parallel implementations of the equivalent operations, with impressive results. 




%----------------------------------------------------------------------------------------

\end{document}
